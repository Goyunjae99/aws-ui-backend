import subprocess
import os
import json
import random
import logging
import sys
import asyncio
import requests
from datetime import datetime
from typing import Dict, Any, Optional, List
from urllib.parse import urlparse

from fastapi import FastAPI, Depends, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from sqlalchemy import create_engine, Column, Integer, String, JSON, DateTime, Boolean, ForeignKey
from sqlalchemy.orm import declarative_base
from sqlalchemy.orm import sessionmaker, Session
from fastapi.responses import FileResponse
from fastapi.staticfiles import StaticFiles
from cryptography.fernet import Fernet

from config import CONFIG
from services.runners.mock_runner import run_mock_provisioning_task

# ==========================================
# 0. ì•”í˜¸í™” ì„¤ì •
# ==========================================
# HARDCODED CONFIG START -- ë‚˜ì¤‘ì— ì‹¤ì œ í‚¤/ì•”í˜¸í™” ì„¤ì •ìœ¼ë¡œ êµì²´
ENCRYPT_KEY = b'U7a9ulzi1i_3CPtT0DK6c76CGSHum7Bi2ujtqIzmwIc='
cipher_suite = Fernet(ENCRYPT_KEY)
# HARDCODED CONFIG END

def encrypt_password(password: str) -> str:
    return cipher_suite.encrypt(password.encode()).decode()

def decrypt_password(encrypted_password: str) -> str:
    return cipher_suite.decrypt(encrypted_password.encode()).decode()

# ==========================================
# 1. ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì • (PostgreSQL + SSH Tunnel)
# ì—°ê²° ì‹¤íŒ¨ ì‹œ SQLite ë¡œì»¬ íŒŒì¼ë¡œ ìë™ í´ë°±í•˜ì—¬ ì•±ì´ ê³„ì† ì‹¤í–‰ë˜ê²Œ í•¨.
# ==========================================

logging.basicConfig(level=logging.INFO)
db_logger = logging.getLogger("uvicorn")
ans_logger = logging.getLogger("uvicorn.error")

# HARDCODED CONFIG START -- TODO: ë‚˜ì¤‘ì— ì‹¤ì œ DB ì •ë³´(vCenter/AWS/ìš´ì˜ DB)ë¡œ êµì²´
SQLALCHEMY_DATABASE_URL = "postgresql://admin:Soldesk1.@localhost:15432/cmp_db"
SQLITE_FALLBACK_URL = "sqlite:///./app.db"
# HARDCODED CONFIG END

Base = declarative_base()


def _create_engine_with_fallback():
    """
    ìš°ì„  PostgreSQL(í•˜ë“œì½”ë”© URL)ë¡œ ì—°ê²° ì‹œë„.
    ì‹¤íŒ¨ ì‹œ(ì˜ˆ: Connection refused) í˜¸ìŠ¤íŠ¸/í¬íŠ¸ì™€ ì‚¬ìœ ë¥¼ ë¡œê·¸ì— ë‚¨ê¸°ê³ 
    SQLite(app.db)ë¡œ ì„ì‹œ ì „í™˜í•˜ì—¬ ì•±ì´ ì£½ì§€ ì•Šê²Œ í•¨.
    """
    primary = SQLALCHEMY_DATABASE_URL
    try:
        engine = create_engine(
            primary,
            pool_size=20,
            max_overflow=10,
            pool_pre_ping=True,
            connect_args={"connect_timeout": 5},
        )
        with engine.connect() as _:
            pass
        return engine
    except Exception as e:
        host, port = "localhost", "15432"
        try:
            parsed = urlparse(primary)
            if parsed.hostname:
                host = parsed.hostname
            if parsed.port is not None:
                port = str(parsed.port)
            else:
                # postgresql://user:pass@host:15432/db í˜•íƒœì—ì„œ host:port ì¶”ì¶œ
                netloc = getattr(parsed, "netloc", "") or ""
                if "@" in netloc:
                    _, hostport = netloc.rsplit("@", 1)
                    if ":" in hostport:
                        host, port = hostport.rsplit(":", 1)
                        port = str(port)
        except Exception:
            pass
        db_logger.warning(
            "DB ì—°ê²° ì‹¤íŒ¨ (host=%s, port=%s, ì‚¬ìœ : %s) â†’ SQLiteë¡œ ì„ì‹œ ì „í™˜",
            host, port, e,
        )
        print("DB ì—°ê²° ì‹¤íŒ¨ â†’ SQLiteë¡œ ì„ì‹œ ì „í™˜")  # ì½˜ì†”ì— ëª…í™•íˆ ì¶œë ¥
        # SQLiteëŠ” pool_size/connect_timeout ë“± ë¶ˆí•„ìš”; ë‹¨ìˆœ ìƒì„±
        return create_engine(SQLITE_FALLBACK_URL, connect_args={"check_same_thread": False})


engine = _create_engine_with_fallback()
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

# ==========================================
# 2. DB í…Œì´ë¸” ëª¨ë¸
# ==========================================
class ProjectHistory(Base):
    __tablename__ = "projects"
    id = Column(Integer, primary_key=True, index=True)
    service_name = Column(String, index=True)
    status = Column(String, default="PROVISIONED")
    assigned_ip = Column(String)
    template_type = Column(String)
    created_at = Column(DateTime, default=datetime.now)
    details = Column(JSON) 

class SystemSetting(Base):
    __tablename__ = "settings"
    id = Column(Integer, primary_key=True, index=True)
    vcenter_ip = Column(String)
    esxi_ip = Column(String, default="192.168.0.200")
    maintenance_mode = Column(Boolean, default=False)
    max_vcpu = Column(Integer, default=100)
    max_memory = Column(Integer, default=256)
    system_notice = Column(String, default="") 
    admin_password = Column(String, default="1234")
    vcenter_user = Column(String)
    vcenter_password = Column(String)

# [ë³€ê²½] ì‹¤ì œ DB ìŠ¤í‚¤ë§ˆì— ë§ì¶˜ WorkloadTestPool
class WorkloadTestPool(Base):
    __tablename__ = "workload_test_pool"
    id = Column(Integer, primary_key=True, index=True)
    vm_name = Column(String)     # WKLD-20
    ip_address = Column(String)  # 192.168.40.20
    is_used = Column(Boolean)    # t/f
    project_id = Column(Integer, nullable=True)
    occupy_user = Column(String, nullable=True)

Base.metadata.create_all(bind=engine)

# ==========================================
# 3. ë°ì´í„° ëª¨ë¸
# ==========================================
class ProjectRequest(BaseModel):
    serviceName: str
    userName: str
    config: Dict[str, Any]
    targetInfra: Dict[str, Any]

class LoginRequest(BaseModel):
    user_id: str
    password: str

class SettingsUpdateRequest(BaseModel):
    vcenter_ip: Optional[str] = ""
    esxi_ip: Optional[str] = ""
    maintenance_mode: bool = False
    max_vcpu: int = 100
    max_memory: int = 256
    system_notice: Optional[str] = ""
    admin_password: str 

# ==========================================
# 4. ì•± ë° Ansible ì„¤ì •
# ==========================================
app = FastAPI()
app.mount("/templates", StaticFiles(directory="templates"), name="templates")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

def get_db():
    db = SessionLocal()
    try:
        if not db.query(SystemSetting).first():
            # ì´ˆê¸° ì„¤ì •ì´ ì—†ìœ¼ë©´ ìƒì„±
            pass 
        yield db
    except Exception as e:
        db_logger.error(f"ğŸš¨ [DB ì—°ê²° ì—ëŸ¬]: {str(e)}")
        raise
    finally:
        db.close()

# Ansible Task (ë¡œì»¬ ì‹œë®¬ë ˆì´ì…˜ìš©ìœ¼ë¡œ ìœ ì§€/ìˆ˜ì • ê°€ëŠ¥í•˜ë‚˜ í•µì‹¬ ë¡œì§ì€ ì•„ë‹˜)
def run_ansible_task(playbook_name: str, extra_vars: dict, project_id: int):
    # (ìƒëµ: ì‹¤ì œ ë°°í¬ ë¡œì§ì´ í•„ìš”í•˜ë‹¤ë©´ ê¸°ì¡´ ì½”ë“œ ë³µêµ¬ ê°€ëŠ¥)
    pass

# í•˜ë“œì½”ë”© ì„¤ì •ì€ config.CONFIG ì—ì„œ ì°¸ì¡° (ê¸°ì¡´ ì½”ë“œ í˜¸í™˜ìš© ë³„ì¹­)
TEMPLATE_MAP = CONFIG["template_map"]

# ==========================================
# 5. API ì—”ë“œí¬ì¸íŠ¸
# ==========================================

@app.post("/api/login")
async def login(req: LoginRequest, db: Session = Depends(get_db)):
    setting = db.query(SystemSetting).first()
    real_pw = setting.admin_password if setting else "1234"
    if req.user_id == "admin" and req.password == real_pw:
        return {"status": "success", "message": "Login Approved"}
    raise HTTPException(status_code=401, detail="ì•„ì´ë””/ë¹„ë²ˆ ë¶ˆì¼ì¹˜")

# [ì‹ ê·œ] Prometheus ë°ì´í„° ì¡°íšŒ í•¨ìˆ˜
# HARDCODED CONFIG START -- TODO: ë‚˜ì¤‘ì— ì‹¤ì œ Prometheus URLë¡œ êµì²´
def query_prometheus(query: str):
    PROMETHEUS_URL = "http://localhost:19090/api/v1/query"  # SSH í„°ë„ë§ëœ ë¡œì»¬ í¬íŠ¸ ê°€ì •
    try:
        response = requests.get(PROMETHEUS_URL, params={'query': query}, timeout=2)
        if response.status_code == 200:
            data = response.json()
            if data['status'] == 'success':
                return data['data']['result']
    except Exception as e:
        print(f"âš ï¸ Prometheus Query Error: {e}")
    return []
# HARDCODED CONFIG END


def _my_resources_from_mock_projects(db: Session) -> List[Dict[str, Any]]:
    """ProjectHistory.details.resources ê°€ ìˆëŠ” í”„ë¡œì íŠ¸ë¥¼ my-resources í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (DB ê¸°ë°˜)."""
    rows = []
    projects = db.query(ProjectHistory).filter(ProjectHistory.details.isnot(None)).all()
    for proj in projects:
        details = proj.details if isinstance(proj.details, dict) else {}
        res = details.get("resources")
        status_detail = details.get("status", proj.status or "")
        if not res:
            continue
        project_name = proj.service_name or "Unknown Project"
        # alb_ip
        alb = res.get("alb_ip")
        if alb:
            rows.append({
                "vm_name": "ALB",
                "ip_address": alb,
                "project_name": project_name,
                "cpu_usage": 0,
                "memory_usage": 0,
                "status": "Running" if status_detail == CONFIG["status_completed"] else status_detail,
            })
        # web_url (ì£¼ì†Œì²˜ëŸ¼ í‘œì‹œ)
        web = res.get("web_url")
        if web:
            rows.append({
                "vm_name": "Web",
                "ip_address": web,
                "project_name": project_name,
                "cpu_usage": 0,
                "memory_usage": 0,
                "status": "Running" if status_detail == CONFIG["status_completed"] else status_detail,
            })
        # db_vip
        dbv = res.get("db_vip")
        if dbv:
            rows.append({
                "vm_name": "DB",
                "ip_address": dbv,
                "project_name": project_name,
                "cpu_usage": 0,
                "memory_usage": 0,
                "status": "Running" if status_detail == CONFIG["status_completed"] else status_detail,
            })
        # ssh_targets
        for i, t in enumerate(res.get("ssh_targets") or []):
            host = t.get("host") if isinstance(t, dict) else str(t)
            if host:
                rows.append({
                    "vm_name": f"SSH-{i + 1}",
                    "ip_address": host,
                    "project_name": project_name,
                    "cpu_usage": 0,
                    "memory_usage": 0,
                    "status": "Running" if status_detail == CONFIG["status_completed"] else status_detail,
                })
    return rows


@app.get("/api/monitoring/my-resources")
async def get_my_resources(db: Session = Depends(get_db)):
    """
    í˜„ì¬ ë¡œê·¸ì¸í•œ ì‚¬ìš©ì(admin ê³ ì •)ì˜ VM ëª©ë¡ì„ DBì—ì„œ ê°€ì ¸ì˜¤ê³ ,
    Mock í”„ë¡œì íŠ¸ì˜ details.resources ë„ í•¨ê»˜ ë°˜í™˜. Prometheus ì—°ë™ì€ ì„ íƒ.
    """
    current_user = "admin"
    result: List[Dict[str, Any]] = []

    # 1. WorkloadTestPool ê¸°ë°˜ ìì› (ê¸°ì¡´ ë™ì‘ ìœ ì§€)
    my_vms = db.query(WorkloadTestPool).filter(
        WorkloadTestPool.occupy_user == current_user,
        WorkloadTestPool.is_used == True
    ).all()

    cpu_query = '100 - (avg by (instance) (rate(node_cpu_seconds_total{mode="idle"}[1m])) * 100)'
    mem_query = '(1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100'
    cpu_data = query_prometheus(cpu_query)
    mem_data = query_prometheus(mem_query)
    metrics_map = {}

    def parse_metrics(results, metric_type):
        for res in results:
            instance = res['metric'].get('instance', '')
            ip = instance.split(':')[0]
            val = float(res['value'][1])
            if ip not in metrics_map:
                metrics_map[ip] = {}
            metrics_map[ip][metric_type] = round(val, 1)

    parse_metrics(cpu_data, 'cpu')
    parse_metrics(mem_data, 'memory')

    for vm in my_vms:
        project_name = "Unknown Project"
        if vm.project_id:
            proj = db.query(ProjectHistory).filter(ProjectHistory.id == vm.project_id).first()
            if proj:
                project_name = proj.service_name
        usage = metrics_map.get(vm.ip_address, {})
        result.append({
            "vm_name": vm.vm_name,
            "ip_address": vm.ip_address,
            "project_name": project_name,
            "cpu_usage": usage.get('cpu', 0),
            "memory_usage": usage.get('memory', 0),
            "status": "Running"
        })

    # 2. Mock í”„ë¡œì íŠ¸ì˜ details.resources ê¸°ë°˜ í•­ëª© ì¶”ê°€ (DB ê¸°ë°˜)
    result.extend(_my_resources_from_mock_projects(db))
    return result


@app.post("/api/provision")
async def create_infrastructure(request: ProjectRequest, background_tasks: BackgroundTasks, db: Session = Depends(get_db)):
    """
    Mock Runner: DBì— PENDING í”„ë¡œì íŠ¸ ìƒì„± í›„ ì¦‰ì‹œ ì‘ë‹µ, ë°±ê·¸ë¼ìš´ë“œì—ì„œ Mock provisioning ì‹¤í–‰.
    """
    user_template = request.config.get('template', 'single')
    input_payload = {
        "serviceName": request.serviceName,
        "userName": request.userName,
        "config": request.config,
        "targetInfra": request.targetInfra,
    }
    details = {
        "input": input_payload,
        "config": request.config,
        "infra": request.targetInfra,
        "status": CONFIG["status_pending"],
        "logs": [],
        "resources": None,
        "error": None,
    }
    new_project = ProjectHistory(
        service_name=request.serviceName,
        status=CONFIG["status_pending"],
        assigned_ip="",
        template_type=user_template,
        details=details,
    )
    db.add(new_project)
    db.commit()
    db.refresh(new_project)

    background_tasks.add_task(run_mock_provisioning_task, new_project.id, input_payload)
    return {"status": "success", "message": f"í”„ë¡œì íŠ¸ #{new_project.id} ìƒì„± ì‹œì‘", "project_id": new_project.id}


@app.delete("/api/provision/{project_id}")
async def delete_project(project_id: int, db: Session = Depends(get_db)):
    project = db.query(ProjectHistory).filter(ProjectHistory.id == project_id).first()
    if not project:
        raise HTTPException(status_code=404, detail="Not Found")
    
    vms = db.query(WorkloadTestPool).filter(WorkloadTestPool.project_id == project_id).all()
    for vm in vms:
        vm.is_used = False
        vm.project_id = None
        vm.occupy_user = None
    
    db.delete(project)
    db.commit()
    return {"status": "success", "message": "ì‚­ì œ ì™„ë£Œ"}

# ... ê¸°íƒ€ ê¸°ì¡´ í˜ì´ì§€ ë¼ìš°íŠ¸ ...
# í…œí”Œë¦¿ ê²½ë¡œ: main.py ê¸°ì¤€ìœ¼ë¡œ ê³ ì • (ì‘ì—… ë””ë ‰í„°ë¦¬ ì˜í–¥ ì—†ìŒ)
_TEMPLATES_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), "templates")

@app.get("/")
async def read_index():
    """ì²« í™”ë©´: ì¸í”„ë¼ ì„ íƒ í˜ì´ì§€ (select_infra)"""
    return FileResponse(os.path.join(_TEMPLATES_DIR, "select_infra(1).html"))

@app.get("/configure")
async def read_configure():
    """AWS ì„ íƒ í›„: Configure & Provision í˜ì´ì§€ (omakase_final)"""
    return FileResponse(os.path.join(_TEMPLATES_DIR, "omakase_final.html"))

@app.get("/history")
async def read_history(): return FileResponse(os.path.join(_TEMPLATES_DIR, "history.html"))

@app.get("/monitoring")
async def read_monitoring(): return FileResponse(os.path.join(_TEMPLATES_DIR, "monitoring.html"))

@app.get("/main_ui")
async def read_main_ui():
    """Expert Mode / Operations: main_ui.html"""
    return FileResponse(os.path.join(_TEMPLATES_DIR, "main_ui.html"))

@app.get("/api/api/history") # (ì˜¤íƒ€ ë°©ì§€ìš©)
@app.get("/api/history")
async def get_history(db: Session = Depends(get_db)):
    return db.query(ProjectHistory).order_by(ProjectHistory.id.desc()).all()

@app.get("/api/public/settings")
async def get_public_settings(db: Session = Depends(get_db)):
    s = db.query(SystemSetting).first()
    return {"system_notice": s.system_notice if s else "", "maintenance_mode": s.maintenance_mode if s else False}

# ì„œë²„ ì‹¤í–‰
if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
